# Public Good Technology Rubric
## A self-assessment for makers of purpose-built tools for civil society

_This is an initial draft of the Public Good Technology Rubric. We will be holding consultations and collecting feedback from stakeholders over the coming months. To offer feedback you can fork this document in GitHub, or email comments to [MakerLabs@TechSoup.org](mailto:MakerLabs@TechSoup.org)._


# What is Public Good Technology?

Most generally, the term refers to technology that is good for the public. 

Some people use terms like “humane” or “ethical” technology, meaning it has been designed with humans in mind (aka human-centered design). There’s also “responsible” technology, which implies a consideration and mitigation of potential harms to users—especially marginalized communities. And finally, “prosocial” technology often describes technology that actively promotes individual or collective wellbeing. 

Public good technology can also sometimes be referred to as “public interest technology.” Some public good or interest technology might also be “civic technology,” which usually refers to publicly funded technology and/or technology that enhances democratic values or processes.

“Digital public goods” are similar to public good technology, but more directly draw from economists' definition of public good as non-excludable (no one can prevent anyone else from using it–such as by charging a high price) and non-rivalrous (no persons consumption impedes anyone else’s consumption), meaning they are notoriously difficult to provide through market-based means and are therefore often provided by governments and/or civil society. Defined by the UN-endorsed DPGA, digital public goods are “open source software, open data, open AI models, open standards and open content that adhere to privacy and other applicable laws and best practices, do no harm, and help attain the SDGs.”

Our definition of public good technology expands upon these different approaches. As an organization that has been providing nonprofits with technological tools for decades, TechSoup views public good technology as technological tools built to support civil society. These tools can sometimes be referred to as “applications” (or “apps”), DApps (apps built on decentralized networks), “products” (commercial tools), or “projects” (open source tools). For the purposes of this rubric, we chose to use the term “tool,” which encompasses all of these different types.

We think a tool can be considered public good technology if its builders have taken a human-centered approach to design, if it employs ethical data practices that do not harm, and has either legally established itself as a nonprofit or has an explicit social impact goal(s) and a roadmap for accomplishing that goal.


# How Will the Rubric Be Used?

The Rubric will be used by:



* **Makers**: to have a self-assessment of the current health of their public good project, and to potentially publish the assessment for either the public or for the broader project team
* **Funders**: to get a broad assessment of the state of public good projects, and to help determine which projects they should be funding
* **Nonprofits, civil society “customers”, and other stakeholders**: to help select software and projects that are mature and values-aligned.
* **TechSoup**: to assess the state of public good projects broadly, and to help select projects for partnerships and inclusion in the TechSoup offers catalog.


# About This Rubric

The goal of this rubric is to engage stakeholders–especially technology makers and civil society integrators–in conversations about approaching specific components of creating, integrating and ongoing use of public good technology. The goal is not to evaluate the quality of the technology, but rather provide a common framework to help makers understand the nuances of building tools for the public benefit and civil society decision-makers with guiding assessment questions for a given technology.

Our thinking about a framework is, so far, based on the structure defined in Tara Dawson McGuinness and Hana Schank's [Power to the Public](https://press.princeton.edu/books/ebook/9780691216638/power-to-the-public). This thinking is augmented with what we found was needed in interviews with the makers of digital solutions and what we have learned from quantitative research on the readiness of civil society organizations to adopt technology.

Of the five areas listed below, three were taken from Power to the Public: Design, Data, and Delivery. Over the course of our engagement in this work, TechSoup has added Impact and Community. Together, these comprise the foundational components from which a more rigorous framework and scoring system for building public good technology can be built.

We’d love your feedback on this rubric. Feel free to reach out to us at [makerlabs@techsoup.org](mailto:makerlabs@techsoup.org).


# Design

These questions aim to encourage Makers to include a diverse array of stakeholders in the design and development of their technologies (inc. UX/UI, algorithms, data processes, etc.). This also includes intentionally designing governance mechanisms for continuous stakeholder participation in ownership and decision-making to ensure long-term sustainability and accountability over time.



* What problem or job is the purpose-built tool being designed to solve/get done? 
* What stakeholders are you including in your design process? These stakeholders should include groups from:
    * Civil Society Organizations (and other user community groups with diverse demographics across race, ethnicity, age, gender, religion, sexual orientation, gender identity, gender expression, disability, economic status and other diverse backgrounds).
    * Funders, whether corporate, institutional foundations, BINGOs, or quasi-governmental groups such as the UN, World Bank, or WHO
    * Foundations, such as Gates, Ford, Rockefeller
    * Government Agencies
    * Community leaders, such as locally recognized leaders that are not affiliated with the other mentioned groups
    * Independent community members, such as journalists, local advocates
* How is input collected from these stakeholders?
    * Are you co-designing user interfaces with civil society and user community members?
    * In what aspects of the design of your tool are you welcoming participation?
    * If your technology employs algorithms, are there mechanisms for users to control or give feedback on their interactions with these algorithms?
* How are stakeholders kept informed about the progress of tool development?
* How is the governance of the project designed? Including:
    * What is the current legal status / business structure of the project (C corp, B corp, LLC, nonprofit, etc.)? 
    * What is the equity/ownership breakdown?
    * Who are the decision-makers/decision-making bodies for the project? (Founding team, advisory board, investors, etc.)
* How does your governance structure help maintain your project’s accountability to its civil society stakeholders?


# Data

These questions aim to help Makers ensure they are engaging in responsible data management practices and taking adequate measures to prevent risks with damaging consequences for users including: sensitive information misuse, identity theft, invasive targeted advertising, and decisions that lead to discrimination and bias. 



* What are the organization’s overall objectives and what data is needed to meet these objectives? (keeping in mind that tools should only collect the data required for them to function)
* How do you get permission to collect this data? Do you give users the ability to opt-out?
* Are you transparent about your data processes with users and actively take steps to educate them about these processes? What terms and conditions are associated with the data?
* How is the data stored to maintain security?
* How do you ensure that data is accurate, complete and current? How often will it be updated and over what period of time?
* How (and by whom) is the data accessed, prepared, and used? And to what end?
* Do you give users easy-to-use tools and interfaces to view, correct, or delete their data?
* Does the data have any relevant standards that apply to it (including standards for quality check, security and privacy, data schema style standards, etc.) and, if so, how does the app work with the standards?
* How are you addressing potential biases in your data?
* Is there any sensitive data being collected that might require higher standards of privacy and care?


# Delivery

These questions aim to help makers better plan for the delivery of their technological tools to civil society user communities. Oftentimes, tools are developed with high impact potential but without any structure for support over time making them virtually useless especially for non-technical adopters. These questions help makers think through the lifecycle of a partnership with a civil society organization–from onboarding, to training, to issue resolution and feedback, to long-term sustainability.



* How is the tool brought to the community? 
* How would you describe how the tool helps non-technical users solve a problem or get something done? What support is available for people getting onto the tool for the first time (onboarding) as well as training for particular roles?
* How are user problems or issues with the tool handled?
* Is there a roadmap for the continued development of the tool and how is that shared with the community?
* How can the community provide feedback on the tool experience and roadmap?
* What is the sustainability model associated with the tool and for how long can the community expect to be able to use the tool?


# Impact

These questions are meant to support makers in articulating the intended impact of their technologies. Technology, like nonprofits, should have some kind of theory of change or explanation for how its intervention is expected to lead to a specific beneficial outcome. Describing this theory of change is important for both makers as well as nonprofits to better understand how a piece of software may be different from other available solutions. 



* What is the theory of change for your tool and where can users read it? Does the user community have any opportunities to validate this theory of change / provide feedback on the expected outcomes?
* How do the data processes above support this theory of change?
* Are data and learnings being made available to the community?
* Is there a structured way to make changes to the project as a result of these learnings? (i.e [Rapid Cycle Evaluation](https://www.air.org/our-capabilities/research-evaluation/rapid-cycle-evaluations))
* How are you sharing your learnings with the broader ecosystem and contributing to the field overall? (i.e. publishing results, sharing data, or other mechanisms)
* Do users and community members have an opportunity to provide feedback on any evaluations?


# Community

These questions are meant to drive community development between civil society decision-makers and the developers of technology solutions–bridging gaps between the ecosystems. Open lines of communication internally as well as communication outward to the surrounding ecosystem leads to higher quality partnership and better-functioning solutions.



* How does outreach to civil society organizations work? Are there any partner organizations supporting outreach?
* Is there content development happening about the technology? Are there any partner organizations supporting content development?
* Do users of the tool have an opportunity to engage with other uses?
* Do users of the tool have an opportunity to engage directly with people who are working on the technology?


# References

Other rubric models for consideration: 



* Superbloom’s User Experience Toolbox for Risk Mitigation and Accessibility: 
* [How To Think About What's Going On in Community…](https://smithery.com/2022/06/15/how-to-use-the-community-power-compass/)(Well-designed framework that serves as a tool for community practitioners. Could be reference for Public Good Tech practitioners)
* [Co-designing Digital Interventions and Technology Projects with Civil Society | weforum.org](https://www3.weforum.org/docs/WEF_Co_designing_Tech_with_Civil_Society_2021.pdf) 
* [The Revenue-Evil Curve: a different way to think about prioritizing public goods funding](https://vitalik.ca/general/2022/10/28/revenue_evil.html)
* [5 Key Steps to Creating a Data Management Strategy | Tableau](https://www.tableau.com/learn/articles/data-management-strategy)
* [What is data management plan? | IBM](https://www.ibm.com/topics/data-management-plan)
* [The Art of Responsible Data Collection and Use: Why Your Organization Needs to Prioritize Responsible Data Practices Now](https://www.linkedin.com/pulse/art-responsible-data-collection-use-why-your-needs-practices-parvez/)
* [Digital public goods - Wikipedia](https://en.wikipedia.org/wiki/Digital_public_goods#:~:text=A%20digital%20public%20good%20is,and%20help%20attain%20the%20SDGs.%22)
